{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()\n",
    "X = normalize(data.data)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)  # Split data into train and test\n",
    "# You can reduce the dimensions to 2 or 3d for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data $$ \\mathcal{X} = \\mathcal{X}_d \\times \\ldots \\times \\mathcal{X}_d $$\n",
    "The Naive Bayes estimate of p(x,y) is given by;\n",
    "$$ \\hat{p}_{NB}(x,y) := \\hat{p}(y)\\prod^{d}_{j=1} \\hat{p}_j(x_j|y), $$\n",
    "where;\n",
    "* $\\hat{p}_{NB}(x,y)$ is the naive bayes posterior distribution that shows the probability of a sample x belonging to the class y.\n",
    "* $\\hat{p}(y)$ is an estimate of $p(y)$ and also the prior distribution for each class\n",
    "* $\\hat{p}_j(x_j|y)$ is the likelihood and estimates of $p(x_j|y), j = {1,...,d}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Naive model, we assume **independence**.\n",
    "\n",
    "The model likelihood is therefore given by; $$ p(x_1, x_2,..., x_n|y) = p(x_1|y) p(x_2|y)...p(x_n|y) $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distribution is given by; $$ p(y|x) = p(x|y)p(y)/Z $$ \n",
    "according to Bayes rule where Z is a scaling factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. TODO 1: Find the number of unique classes in y\n",
    " 2. TODO 2: Calculate the gaussian likelihood p(x) for x given their means and variance\n",
    " $$ p(y_{i}|x) = \\frac^{1}_{N_i}\\sum^{K}_{k=1}x_ik $$\n",
    " 3. TODO 3: Compute prior for each class\n",
    " 4. TODO 4: Compute posterior for each class\n",
    " 5. TODO 5: Return the class with the largest posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    \"\"\"The Gaussian Naive Bayes classifier. \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "        self.classes = None # TODO 1\n",
    "        self.params = []\n",
    "        \n",
    "        for i, c in enumerate(self.classes):\n",
    "            \n",
    "            X_where_c = X[np.where(y == c)]   # Separate X into their various classes\n",
    "            self.params.append([])            \n",
    "            \n",
    "            # Compute the means and variances for each class\n",
    "            for col in X_where_c.T:\n",
    "                params = {\"mean\": np.mean(col), \"var\": np.cov(col)}\n",
    "                self.params[i].append(params)\n",
    "\n",
    "            \n",
    "    def _calculate_likelihood(self, mean, var, x):  \n",
    "        \"\"\" Gaussian likelihood of the data x given mean and var \"\"\"\n",
    "        eps = 1e-4 # AAdd a small-valued epsilon to prevent division by 0\n",
    "        #TODO 2\n",
    "        pass\n",
    "\n",
    "    def _calculate_prior(self, c):\n",
    "        \"\"\" Calculate the prior of class c\n",
    "        (samples belonging to class c / total number of samples)\"\"\"\n",
    "        p = None # TODO 3\n",
    "        return p\n",
    "\n",
    "    def _classify(self, sample):\n",
    "        \"\"\" \n",
    "        P(y|x) - posterior probability\n",
    "        P(x|y) - data likelihood\n",
    "        P(y)   - Prior distribution over classes\n",
    "        P(x)   - marginal distribution of x that scalees the probability distribution to a range between 0 and 1\n",
    "        \"\"\"\n",
    "        posteriors = []\n",
    "        # Go through list of classes\n",
    "        for i, c in enumerate(self.classes):\n",
    "            # Initialize posterior as prior\n",
    "            posterior = self._calculate_prior(c)           \n",
    "           \n",
    "            for feature_value, param in zip(sample, self.params[i]):\n",
    "                # Likelihood of feature value given distribution of feature values given y\n",
    "                likelihood = self._calculate_likelihood(param[\"mean\"], param[\"var\"], feature_value)\n",
    "                posterior = None # TODO 4 --- Multiply the likelihoods with prior\n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        return None # TODO 5\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict the class labels of each sample in X \"\"\"\n",
    "        y_pred = [self._classify(x_i) for x_i in X]\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NaiveBayes()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print (\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
